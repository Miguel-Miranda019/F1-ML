{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865aa454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "#from langgraph.prebuilt import ToolExecutor, chat_agent_executor\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, SystemMessage, ToolMessage, AIMessage\n",
    "\n",
    "from typing import TypedDict, List, Union, Annotated\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import operator\n",
    "\n",
    "import fastf1\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3ec130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified compare_driver_laps function\n",
    "def compare_driver_laps(year: int, gp: str, session_type: str, driver1: str, driver2: str):\n",
    "    session = fastf1.get_session(year, gp, session_type)\n",
    "    session.load()\n",
    "\n",
    "    lap1 = session.laps.pick_drivers(driver1).pick_fastest()\n",
    "    lap2 = session.laps.pick_drivers(driver2).pick_fastest()\n",
    "\n",
    "    tel1 = lap1.get_car_data().add_distance()\n",
    "    tel2 = lap2.get_car_data().add_distance()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    plt.plot(tel1['Distance'], tel1['Speed'], label=driver1)\n",
    "    plt.plot(tel2['Distance'], tel2['Speed'], label=driver2)\n",
    "    plt.xlabel('Distance (m)')\n",
    "    plt.ylabel('Speed (km/h)')\n",
    "    plt.title(f'{driver1} vs {driver2} - Fastest Lap Speed Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    image_path = \"comparison.png\"\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()  # Important to close the figure\n",
    "    \n",
    "    # Return both the image path and lap times\n",
    "    return {\n",
    "        \"image_path\": image_path,\n",
    "        \"lap_times\": {\n",
    "            driver1: str(lap1['LapTime']),\n",
    "            driver2: str(lap2['LapTime'])\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0925eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.simple.Tool'>\n",
      "CompareDriverLaps\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Wrap this function as a LangChain tool\n",
    "\n",
    "#tool = Tool(\n",
    "#    name=\"CompareDriverLaps\",\n",
    "#    func=lambda x: compare_driver_laps(**eval(x)),\n",
    "#    description=\"Use this tool to generate a lap speed comparison plot between two drivers. Input should be a dictionary with keys: year, gp, session_type, driver1, driver2.\"\n",
    "#)\n",
    "#print(type(tool))\n",
    "#print(tool.name)\n",
    "\n",
    "# Cell 4: LangChain Tool wrapper\n",
    "tool = Tool(\n",
    "    name=\"CompareDriverLaps\",\n",
    "    func=lambda x: compare_driver_laps(**json.loads(x) if isinstance(x, str) else x),\n",
    "    description=(\n",
    "        \"Use this tool to generate a lap speed comparison plot between two drivers. \"\n",
    "        \"Input must be a dictionary with keys: year, gp, session_type, driver1, driver2. \"\n",
    "        \"Example: {\\\"year\\\": 2023, \\\"gp\\\": \\\"Monaco\\\", \\\"session_type\\\": \\\"Q\\\", \\\"driver1\\\": \\\"VER\\\", \\\"driver2\\\": \\\"LEC\\\"}\"\n",
    "    )\n",
    ")\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e930b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7848708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_ollama)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "            \n",
    "        )\n",
    "        graph.add_edge(\"action\",\"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "    \n",
    "    \n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "    \n",
    "    \n",
    "    def call_ollama(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}    \n",
    "    \n",
    "    # Modified take_action method in the Agent class\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "                # If the result contains an image path, display it\n",
    "                if isinstance(result, dict) and \"image_path\" in result:\n",
    "                    display(Image(result[\"image_path\"]))\n",
    "                    result = f\"Comparison complete. Lap times: {result['lap_times']}\"\n",
    "        \n",
    "            results.append(ToolMessage(\n",
    "                tool_call_id=t['id'],\n",
    "                name=t['name'],\n",
    "                content=str(result)\n",
    "            ))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e8dd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test the agent with the modified code\n",
    "prompt = \"\"\"You are a smart F1 assistant.\n",
    "You can compare drivers using telemetry and lap times. call tools to help.\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1\")\n",
    "abot = Agent(model=model, tools=[tool], system=prompt)\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Compare Max Verstappen and Charles Leclerc in the 2023 Monaco GP qualifying. Also tell me who was faster.\")\n",
    "]\n",
    "\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d9eb565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Compare Max Verstappen and Charles Leclerc in the 2023 Monaco GP qualifying. Also tell me who was faster.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='{\"name\": \"CompareDriverLaps\", \"parameters\": {\"year\": \"2023\", \"gp\": \"Monaco\", \"session_type\": \"Q\", \"driver1\": \"VER\", \"driver2\": \"LEC\"}} \\n\\nNote: The tool will generate a lap speed comparison plot and provide the results, including who was faster.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-07-22T22:45:10.2875759Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1233624400, 'load_duration': 23580900, 'prompt_eval_count': 277, 'prompt_eval_duration': 2757300, 'eval_count': 70, 'eval_duration': 1206272300, 'model_name': 'llama3.1'}, id='run--484bc477-8027-456c-a004-4c39fae47239-0', usage_metadata={'input_tokens': 277, 'output_tokens': 70, 'total_tokens': 347})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1dd18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"CompareDriverLaps\", \"parameters\": {\"year\": \"2023\", \"gp\": \"Monaco\", \"session_type\": \"Q\", \"driver1\": \"VER\", \"driver2\": \"LEC\"}}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content  # This will contain the plot or the result of the tool call"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
